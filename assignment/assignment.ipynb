{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
   "metadata": {
    "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
   },
   "source": [
    "# Assignment: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
   "metadata": {
    "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
   },
   "source": [
    "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
    "\n",
    "  1. Read the abstract. What is this paper about?\n",
    "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
    "  3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, itâ€™s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
    "  4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
    "  5. How is \"Tidy Data\" defined in section 2.3?\n",
    "  6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
    "  7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
    "  8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e32cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n1. The paper is about creating tidy dataidk\\n2. It's intended to accomplish idk\\n3. When cleaning data, ther is a uniform standard to clean towards in order to be able to use the data. However, data at its original form are inconsistent with each other and have different unique parts to clean in order to become uniform.\\n   It's hard to define what variables and observations are.\\n4. Wichkam defines values, variables, and observations as\\n5. Tidy data is idk\\n6. The datain the table is messy because, it's a meltiing dataset\\n7. Table 11 is messy but table 12 is molten because\\n8. The chicken and egg problem is\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. The paper is about creating tidy dataidk\n",
    "2. It's intended to accomplish idk\n",
    "3. When cleaning data, ther is a uniform standard to clean towards in order to be able to use the data. However, data at its original form are inconsistent with each other and have different unique parts to clean in order to become uniform.\n",
    "   It's hard to define what variables and observations are.\n",
    "4. Wichkam defines values, variables, and observations as\n",
    "5. Tidy data is idk\n",
    "6. The datain the table is messy because, it's a meltiing dataset\n",
    "7. Table 11 is messy but table 12 is molten because\n",
    "8. The chicken and egg problem is\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
   "metadata": {
    "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
   },
   "source": [
    "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
    "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
    "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
    "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
    "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a35d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "363909fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.read_csv('./data/airbnb_hw.csv',low_memory=False)\n",
    "sdf = pd.read_csv('./data/sharks.csv', low_memory=False)\n",
    "pdf = pd.read_csv( 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv' ,low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89352e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host Id</th>\n",
       "      <th>Host Since</th>\n",
       "      <th>Name</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Review Scores Rating (bin)</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Number Of Reviews</th>\n",
       "      <th>Price</th>\n",
       "      <th>Review Scores Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5162530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Bedroom in Prime Williamsburg</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>11249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33134899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunny, Private room in Bushwick</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private room</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39608626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunny Room in Harlem</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private room</td>\n",
       "      <td>10032.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>6/26/2008</td>\n",
       "      <td>Gorgeous 1 BR with Private Balcony</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10024.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>6/26/2008</td>\n",
       "      <td>Trendy Times Square Loft</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Private room</td>\n",
       "      <td>10036.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>549</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Host Id Host Since                                Name Neighbourhood   \\\n",
       "0   5162530        NaN     1 Bedroom in Prime Williamsburg       Brooklyn   \n",
       "1  33134899        NaN     Sunny, Private room in Bushwick       Brooklyn   \n",
       "2  39608626        NaN                Sunny Room in Harlem      Manhattan   \n",
       "3       500  6/26/2008  Gorgeous 1 BR with Private Balcony      Manhattan   \n",
       "4       500  6/26/2008            Trendy Times Square Loft      Manhattan   \n",
       "\n",
       "  Property Type  Review Scores Rating (bin)        Room Type  Zipcode  Beds  \\\n",
       "0     Apartment                         NaN  Entire home/apt  11249.0   1.0   \n",
       "1     Apartment                         NaN     Private room  11206.0   1.0   \n",
       "2     Apartment                         NaN     Private room  10032.0   1.0   \n",
       "3     Apartment                         NaN  Entire home/apt  10024.0   3.0   \n",
       "4     Apartment                        95.0     Private room  10036.0   3.0   \n",
       "\n",
       "   Number of Records  Number Of Reviews Price  Review Scores Rating  \n",
       "0                  1                  0   145                   NaN  \n",
       "1                  1                  1    37                   NaN  \n",
       "2                  1                  1    28                   NaN  \n",
       "3                  1                  0   199                   NaN  \n",
       "4                  1                 39   549                  96.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d29c947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        145\n",
      "1         37\n",
      "2         28\n",
      "3        199\n",
      "4        549\n",
      "        ... \n",
      "30473    300\n",
      "30474    125\n",
      "30475     80\n",
      "30476     35\n",
      "30477     80\n",
      "Name: Price, Length: 30478, dtype: int64\n",
      "Total Missings: \n",
      " 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. \n",
    "How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
    "\"\"\"\n",
    "# Check the variable\n",
    "var = \"Price\"\n",
    "print(sdf[var])\n",
    "print(sdf[var].unique(), '\\n')\n",
    "\n",
    "# First, remove commas in order to turn the values into numbers.\n",
    "adf[var]= adf[var].str.replace(\",\", \"\")\n",
    "\n",
    "# After cleaning the commas, it's posible to turn price from string to numeric.\n",
    "adf[var] = pd.to_numeric(adf[var], errors='coerce')\n",
    "\n",
    "print(adf[var])\n",
    "print('Total Missings: \\n', sum(adf[var].isnull()),'\\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33126da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unprovoked' 'Provoked' 'Questionable' 'Watercraft' 'Unconfirmed'\n",
      " 'Unverified' 'Invalid' 'Under investigation' 'Boating' 'Sea Disaster' nan\n",
      " 'Boat' 'Boatomg'] \n",
      "\n",
      "['Unprovoked' 'Provoked' 'Questionable' 'Watercraft' 'Unconfirmed'\n",
      " 'Unverified' 'Invalid' 'Under investigation' 'Boating' 'Sea Disaster' nan\n",
      " 'Boat' 'Boatomg'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "2. Categorical variable: \n",
    "For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
    "\"\"\"\n",
    "# Check the variable\n",
    "var = \"Type\"\n",
    "print(sdf[var].unique(), '\\n')\n",
    "\n",
    "# There are lots of different variations of 'Boat' (ex. Boating, Boat, Boatomg, possibly Watercraft) which can be consolidated the types together.\n",
    "sdf.replace(to_replace=[\"Boating\", \"Boatomg\", \"Watercraft\"], value=\"Boat\")\n",
    "\n",
    "# There are also lots of different variations of unknown type of shark attack which can be replaced as nan.\n",
    "sdf.replace(to_replace=[\"Unverified\", \"Under Investigation\", \"Unconfirmed\", \"Questionable\", \"Invalid\"], value=np.nan)\n",
    "\n",
    "print(sdf[var].unique(), '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd576a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        9\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "22981    1\n",
      "22982    1\n",
      "22983    1\n",
      "22984    1\n",
      "22985    1\n",
      "Name: WhetherDefendantWasReleasedPretrial, Length: 22986, dtype: int64\n",
      "[9 0 1] \n",
      "\n",
      "[ True False] \n",
      "\n",
      "WhetherDefendantWasReleasedPretrial\n",
      "True     19185\n",
      "False     3801\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "3. Dummy variable: \n",
    "For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, \n",
    "and, in particular, replace missing values with `np.nan`.\n",
    "\"\"\"\n",
    "# Check the variable\n",
    "var = \"WhetherDefendantWasReleasedPretrial\"\n",
    "print(pdf[var])\n",
    "print(pdf[var].unique(), '\\n')\n",
    "\n",
    "# Replace the 9s as not a number as it's Unclear.\n",
    "pdf[var] = pdf[var].replace( [9], np.nan)\n",
    "\n",
    "# Change to boolean, 1 represents Released while 0 represents Unreleased\n",
    "pdf[var] = pdf[var].astype('bool')\n",
    "# pdf[var] = np.where(pdf[var] == 1, True, False)\n",
    "\n",
    "print(pdf[var].unique(), '\\n')\n",
    "print(pdf[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eb6e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ' '60' '12' '.985626283367556' '36' '6' '24' '5.91375770020534' '120'\n",
      " '72' '11.9917864476386' '0' '2.95687885010267' '84' '108' '300' '240'\n",
      " '180' '4' '96' '2' '54' '.328542094455852' '44' '5' '115' '132' '48'\n",
      " '258' '34' '76' '.164271047227926' '.131416837782341' '111' '9' '3'\n",
      " '1.97125256673511' '36.9856262833676' '.0657084188911704'\n",
      " '35.4928131416838' '106.492813141684' '8' '35' '18.3141683778234' '480'\n",
      " '32' '93' '234' '732' '1.16427104722793' '4.6570841889117' '21' '7'\n",
      " '4.49281314168378' '18' '600' '43.1642710472279' '179' '52' '30' '20'\n",
      " '192' '702' '14' '55' '53' '11.9055441478439' '114' '35.0061601642711'\n",
      " '68' '.657084188911704' '46.6242299794661' '102' '65' '200' '57'\n",
      " '24.3285420944559' '12.1642710472279' '117' '81.4928131416838'\n",
      " '22.4928131416838' '1980' '3.6570841889117' '56' '10' '2.79260780287474'\n",
      " '1' '47' '22' '1500' '40' '284' '11' '118' '42' '162' '156'\n",
      " '47.2956878850103' '105' '51' '246' '29' '75' '324' '360'\n",
      " '34.4804928131417' '120.328542094456' '59.9260780287474' '66'\n",
      " '59.9917864476386' '660' '51.1642710472279' '14.9568788501027'\n",
      " '3.98562628336756' '78' '228' '1.47843942505133' '62' '4.8' '86' '168'\n",
      " '23' '33' '48.0328542094456' '720' '348' '1200' '27' '49' '87' '420' '63'\n",
      " '79.9260780287474' '57.0349075975359' '49.9712525667351'\n",
      " '59.4928131416838' '17' '238.492813141684' '60.9856262833676' '126' '45'\n",
      " '158' '216' '227' '42.9568788501027' '445' '70.952772073922' '516'\n",
      " '177.82135523614' '1752' '90' '1080' '141' '4.82956878850103' '230' '31'\n",
      " '2208' '52.5133470225873' '69' '26' '33.4928131416838' '140' '131' '344'\n",
      " '219' '101' '71' '59' '58' '120.197125256674' '67' '35.4004106776181'\n",
      " '3.28542094455852' '40.1642710472279' '91' '1.7741273100616' '155'\n",
      " '34.4928131416838' '81' '92.3285420944559' '3.5482546201232' '207' '74'\n",
      " '518' '28' '8.95687885010267' '237' '404.673511293634' '18.1642710472279'\n",
      " '10.7433264887064' '551' '39' '15' '124' '43' '176' '19.4928131416838'\n",
      " '482' '129' '88' '46' '45.8542094455852' '128.628336755647'\n",
      " '136.492813141684' '108.328542094456' '50' '363.663244353183' '288' '250'\n",
      " '107' '81.0225872689938' '444' '205' '10.6570841889117' '19'\n",
      " '66.9856262833676' '38.4928131416838' '264' '276' '173' '222' '144' '294'\n",
      " '336' '431' '450' '73' '99.3285420944559' '128' '30.8069815195072'\n",
      " '31.5256673511294' '127' '202' '55.3285420944559' '89' '242'\n",
      " '1.31416837782341' '1029' '.788501026694045' '194.858316221766' '399'\n",
      " '39.6570841889117' '56.95687885' '198' '120.985626283368'\n",
      " '47.6570841889117' '148' '6.8993839835729' '65.3285420944559'\n",
      " '5.95277207392197' '.0985626283367557' '3.32854209445585'\n",
      " '3.94250513347023' '12.9856262833676' '6.98562628336756'\n",
      " '13.1498973305955' '15.1642710472279' '17.1971252566735'\n",
      " '17.9137577002053' '104' '212' '24.6570841889117' '72.6570841889117'\n",
      " '2.98562628336756' '144.985626283368' '31.9712525667351' '183'\n",
      " '4.98562628336756' '11.8213552361396' '252' '12.394250513347'\n",
      " '42.4928131416838' '10.1642710472279' '11.1642710472279'\n",
      " '5.49281314168378' '59.6632443531827' '12.3285420944559'\n",
      " '48.9856262833676' '240.985626283368' '2.6570841889117' '540'\n",
      " '2.97125256673511' '6.32854209445585' '23.6632443531828'\n",
      " '133.657084188912' '35.3285420944559' '456' '103' '1.72279260780287'\n",
      " '12.6570841889117' '11.6570841889117' '60.3285420944559'\n",
      " '3.78850102669405' '576' '2.13141683778234' '492' '14.9856262833676'\n",
      " '24.9856262833676' '61.9712525667351' '5.6570841889117' '16'\n",
      " '42.1642710472279' '.492813141683778' '138' '13.3141683778234'\n",
      " '11.8932238193018' '5.32854209445585' '95' '62.6570841889117'\n",
      " '3.08829568788501' '11.8275154004107' '1.64271047227926'\n",
      " '47.9917864476386' '4.27104722792608' '8.32854209445585'\n",
      " '3.31416837782341' '70' '77' '1.09856262833676' '48.1642710472279'\n",
      " '27.4928131416838' '6.93839835728953' '1011' '.68993839835729'\n",
      " '1.1170431211499' '1.49281314168378' '4.16427104722793'\n",
      " '1.19712525667351' '4.07392197125257' '188' '11.3285420944559'\n",
      " '.0328542094455852' '432' '11.952772073922' '36.4928131416838'\n",
      " '23.9835728952772' '9.98562628336756' '98' '36.3285420944559' '112'\n",
      " '.394250513347023' '13' '.262833675564682' '13.7987679671458'\n",
      " '5.8870636550308' '354' '5.91991786447639' '24.1642710472279'\n",
      " '62.95687885' '4.59958932238193' '123' '2.32854209445585'\n",
      " '23.9240246406571' '204' '197' '174' '16.1498973305955' '840' '440'\n",
      " '98.95687885' '17.952772073922' '63.9425051334702' '60.1314168377823'\n",
      " '12.1314168377823' '172.952772073922' '.197125256673511'\n",
      " '138.164271047228' '4.92813141683778' '.919917864476386'\n",
      " '18.9856262833676' '6.6570841889117' '2.85420944558522'\n",
      " '8.91375770020534' '146' '12.4928131416838' '.558521560574949'\n",
      " '.722792607802875' '5.82135523613963' '84.9856262833676'\n",
      " '6.16427104722793' '15.9856262833676' '64.5585215605749'\n",
      " '38.299794661191' '11.958932238193' '3.1211498973306' '126.328542094456'\n",
      " '5.16427104722793' '64' '42.6570841889117' '312' '19.9712525667351'\n",
      " '82.3285420944559' '23.9712525667351' '17.6242299794661'\n",
      " '121.971252566735' '59.6550308008214' '1.32854209445585'\n",
      " '7.97125256673511' '1.91991786447639' '.525667351129363'\n",
      " '9.32854209445585' '42.9856262833676' '41.9137577002053'\n",
      " '72.9856262833676' '12.4784394250513' '5.19096509240246' '473'\n",
      " '16.6570841889117' '109' '86.3285420944559' '41' '1.90554414784394'\n",
      " '94.1642710472279' '302' '4.39425051334702' '10.8213552361396'\n",
      " '18.3285420944559' '154' '83' '110.956878850103' '226' '96.0328542094456'\n",
      " '4.82135523613963' '30.3285420944559' '37.9712525667351'\n",
      " '50.4640657084189' '286' '99' '99.4928131416838' '2.6611909650924'\n",
      " '70.9712525667351' '13.9712525667351' '23.6570841889117'\n",
      " '.459958932238193' '132.492813141684' '283' '49.3141683778234'\n",
      " '27.9856262833676' '38' '7.6570841889117' '83.6550308008214'\n",
      " '10.9199178644764' '162.328542094456' '37' '132.328542094456'\n",
      " '35.952772073922' '165' '10.9856262833676' '20.1642710472279'\n",
      " '2.59137577002053' '175' '180.985626283368' '10.3285420944559'\n",
      " '36.1642710472279' '120.657084188912' '232' '152' '8.98562628336756'\n",
      " '167' '11.0657084188912' '11.2032854209446' '5.19712525667351'\n",
      " '3.16427104722793' '60.1642710472279' '1.18275154004107'\n",
      " '21.1642710472279' '2.19712525667351' '4.19712525667351'\n",
      " '2.62833675564682' '119.952772073922' '119.958932238193'\n",
      " '9.49281314168378' '5.25667351129363' '15.3285420944559'\n",
      " '2.82135523613963' '192.985626283368' '48.6570841889117'\n",
      " '5.95687885010267' '2.29979466119097' '960' '2.36550308008214' '116'\n",
      " '19.5133470225873' '1.6570841889117'] \n",
      "\n",
      "[9 0 1 4 2] \n",
      "\n",
      "Total Missings: \n",
      " 9053 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SentenceTypeAllChargesAtConvictionInContactEvent</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImposedSentenceAllChargeInContactEvent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>4953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.032854</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.065708</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.098563</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.131417</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SentenceTypeAllChargesAtConvictionInContactEvent     0   1  2     4\n",
       "ImposedSentenceAllChargeInContactEvent                             \n",
       "0.000000                                          4953   0  0  8779\n",
       "0.032854                                             0   6  0     0\n",
       "0.065708                                             3  21  0     0\n",
       "0.098563                                             2   6  0     0\n",
       "0.131417                                             4  10  0     0\n",
       "...                                                ...  .. ..   ...\n",
       "1200.000000                                          0   0  1     0\n",
       "1500.000000                                          0   0  1     0\n",
       "1752.000000                                          0   0  1     0\n",
       "1980.000000                                          0   0  1     0\n",
       "2208.000000                                          0   0  1     0\n",
       "\n",
       "[483 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "4. Missing values, not at random: \n",
    "For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. \n",
    "(Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)\n",
    "\"\"\"\n",
    "# Check the variables\n",
    "var = \"ImposedSentenceAllChargeInContactEvent\"\n",
    "type = \"SentenceTypeAllChargesAtConvictionInContactEvent\"\n",
    "print(pdf[var].unique(), '\\n')\n",
    "print(pdf[type].unique(), '\\n')\n",
    "\n",
    "pd.crosstab(pdf[var], pdf[type])\n",
    "\n",
    "# Turn sentence length from object to numeric and check the amount of missing values\n",
    "pdf[var] = pd.to_numeric(pdf[var], errors='coerce')\n",
    "print('Total Missings: \\n', np.sum(pdf[var].isnull()),'\\n')\n",
    "\n",
    "# In the codebook, sentence type 4 represents dismissed charges so change the sentence length to 0\n",
    "pdf.loc[pdf[type] == 4, var] = 0\n",
    "\n",
    "# In the codebook, sentence type 9 represents N/A charges so change to N/A\n",
    "pdf.loc[pdf[type] == 9, var] = np.nan\n",
    "\n",
    "pd.crosstab(pdf[var], pdf[type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7489057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missings: \n",
      " 274 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Total Missings: \\n', np.sum(pdf[var].isnull()),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
   "metadata": {
    "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
   },
   "source": [
    "**Q3.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
    "\n",
    "1. How did the most recent US Census gather data on race?\n",
    "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
    "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
    "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
    "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
    "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
